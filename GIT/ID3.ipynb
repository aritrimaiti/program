{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPVHnuAtILoEUcJcm2nVMM2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"mkYtC5fezqi-"},"outputs":[],"source":["import math\n","import csv\n","def load_csv(filename):\n","    lines=csv.reader(open(filename,\"r\"))\n","    dataset=list(lines)\n","    headers=dataset.pop(0)\n","    return dataset,headers\n","class Node:\n","    def __init__(self,attribute):\n","        self.attribute=attribute\n","        self.children=[]\n","        self.answer=\"\"\n","def subtables(data,col,delete):\n","    dic={}\n","    coldata=[row[col] for row in data]\n","    attr=list(set(coldata))\n","    for k in attr:\n","        dic[k]=[]\n","    for y in range(len(data)):\n","        key=data[y][col]\n","        if delete:\n","            del data[y][col]\n","        dic[key].append(data[y])\n","    return attr,dic\n","def entropy(s):\n","    attr=list(set(s))\n","    if len(attr)==1:\n","        return 0\n","    counts=[0,0]\n","    for i in range(2):\n","        counts[i]=sum([1 for x in s if attr[i]==x])/(len(s)*1.0)\n","    sums=0\n","    for cnt in counts:\n","        sums+=-1*cnt*math.log(cnt,2)\n","    return sums\n","def compute_gain(data,col):\n","    attValues,dic=subtables(data,col,delete=False)\n","    total_entropy=entropy([row[-1] for row in data])\n","    for x in range(len(attValues)):\n","        ratio=len(dic[attValues[x]])/(len(data)*1.0)\n","        entro=entropy([row[-1] for row in dic[attValues[x]]])\n","        total_entropy=ratio*entro\n","    return total_entropy\n","def build_tree(data,features):\n","    lastcol=[row[-1] for row in data]\n","    if(len(set(lastcol)))==1:\n","        node=Node(\"\")\n","        node.answer=lastcol[0]\n","        return node\n","    n=len(data[0])-1\n","    gains=[compute_gain(data,col) for col in range(n)]\n","    split=gains.index(max(gains))\n","    node=Node(features[split])\n","    fea=features[:split]+features[split+1:]\n","    attr,dic=subtables(data,split,delete=True)\n","    for x in range(len(attr)):\n","        child=build_tree(dic[attr[x]],fea)\n","        node.children.append((attr[x],child))\n","    return node\n","def print_tree(node,level):\n","    if node.answer!=\"\":\n","        print(\" \"*level,node.answer)\n","        return\n","    print(\" \"*level,node.attribute)\n","    for value,n in node.children:\n","        print(\" \"*(level+1),value)\n","        print_tree(n,level+2)\n","def classify(node,xtest,features):\n","    if node.answer!=\"\":\n","        print(node.answer)\n","        return\n","    pos=features.index(node.attribute)\n","    for value,n in node.children:\n","        if xtest[pos]==value:\n","            classify(n,xtest,features)\n","datasets,features=load_csv(\"train_weather.csv\")\n","node=build_tree(datasets,features)\n","print(\"The decision tree for the dataset using ID3 algorithm is\")\n","print_tree(node,0)\n","testdata,features=load_csv(\"test_weather.csv\")\n","for xtest in testdata:\n","    print(\"The test instance:\",xtest)\n","    print(\"The predicted label:\",end=\" \")\n","    classify(node,xtest,features)"]}]}